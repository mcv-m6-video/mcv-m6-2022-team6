{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Training Siamese"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import torch as th\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from siamese import Siamese\n",
    "import os\n",
    "import pandas as pd\n",
    "from dataset import CarDataset\n",
    "\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((64,64)),\n",
    "    transforms.ToTensor()\n",
    "])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 38074 Test size 6174\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('patches/gt_car_patches_annotations.csv', delimiter=',')\n",
    "\n",
    "train = dataset[(dataset.SEQ == 'S01') | (dataset.SEQ == 'S04')]\n",
    "test = dataset[(dataset.SEQ == 'S03')]\n",
    "\n",
    "# Dataset\n",
    "trainSet = CarDataset(train, transform=data_transforms)\n",
    "testSet = CarDataset(test, transform=data_transforms)\n",
    "\n",
    "trainLoader = DataLoader(trainSet, batch_size=256, shuffle=False, num_workers=4)\n",
    "testLoader = DataLoader(testSet, batch_size=10, shuffle=False, num_workers=4)\n",
    "\n",
    "print(f\"Train size: {train.shape[0]} Test size {test.shape[0]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class ContrastiveLoss(th.nn.Module):\n",
    "    \"\"\"\n",
    "    Contrastive loss function.\n",
    "    Based on:\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, x0, x1, y):\n",
    "        # euclidian distance\n",
    "        diff = x0 - x1\n",
    "        dist_sq = th.sum(th.pow(diff, 2), 1)\n",
    "        dist = th.sqrt(dist_sq)\n",
    "\n",
    "        mdist = self.margin - dist\n",
    "        dist = th.clamp(mdist, min=0.0)\n",
    "        loss = y * dist_sq + (1 - y) * th.pow(dist, 2)\n",
    "        loss = th.sum(loss) / 2.0 / x0.size()[0]\n",
    "        return loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use gpu: 0 to train.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "labels must be a 1D tensor of shape (batch_size,)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [7]\u001B[0m, in \u001B[0;36m<cell line: 31>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     39\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m     40\u001B[0m output \u001B[38;5;241m=\u001B[39m net\u001B[38;5;241m.\u001B[39mforward(img1, img2)\n\u001B[0;32m---> 41\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[43mloss_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     42\u001B[0m loss_val \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n\u001B[1;32m     43\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/M6_Video/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/M6_Video/lib/python3.9/site-packages/pytorch_metric_learning/losses/base_metric_loss_function.py:34\u001B[0m, in \u001B[0;36mBaseMetricLossFunction.forward\u001B[0;34m(self, embeddings, labels, indices_tuple, ref_emb, ref_labels)\u001B[0m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;124;03m    embeddings: tensor of size (batch_size, embedding_size)\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;124;03mReturns: the loss\u001B[39;00m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreset_stats()\n\u001B[0;32m---> 34\u001B[0m \u001B[43mc_f\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcheck_shapes\u001B[49m\u001B[43m(\u001B[49m\u001B[43membeddings\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     35\u001B[0m labels \u001B[38;5;241m=\u001B[39m c_f\u001B[38;5;241m.\u001B[39mto_device(labels, embeddings)\n\u001B[1;32m     36\u001B[0m ref_emb, ref_labels \u001B[38;5;241m=\u001B[39m c_f\u001B[38;5;241m.\u001B[39mset_ref_emb(embeddings, labels, ref_emb, ref_labels)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/M6_Video/lib/python3.9/site-packages/pytorch_metric_learning/utils/common_functions.py:419\u001B[0m, in \u001B[0;36mcheck_shapes\u001B[0;34m(embeddings, labels)\u001B[0m\n\u001B[1;32m    415\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    416\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124membeddings must be a 2D tensor of shape (batch_size, embedding_size)\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    417\u001B[0m     )\n\u001B[1;32m    418\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m labels\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m--> 419\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlabels must be a 1D tensor of shape (batch_size,)\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mValueError\u001B[0m: labels must be a 1D tensor of shape (batch_size,)"
     ]
    }
   ],
   "source": [
    "gpu_ids = \"0\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu_ids\n",
    "print(\"use gpu:\", gpu_ids, \"to train.\")\n",
    "\n",
    "cuda = True\n",
    "epochs = 10\n",
    "\n",
    "# Declare Siamese Network\n",
    "net = Siamese().cuda()\n",
    "# Decalre Loss Function\n",
    "criterion = ContrastiveLoss()\n",
    "# Declare Optimizer\n",
    "optimizer = th.optim.Adam(net.parameters(), lr=1e-3, weight_decay=0.0005)\n",
    "\n",
    "#train the model\n",
    "def train():\n",
    "    loss=[]\n",
    "    counter=[]\n",
    "    iteration_number = 0\n",
    "    for epoch in range(1, epochs):\n",
    "\n",
    "        for i, data in enumerate(trainLoader,0):\n",
    "\n",
    "            img0, img1 , label = data\n",
    "            img0, img1 , label = img0.cuda(), img1.cuda() , label.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            output1, output2 = net(img0,img1)\n",
    "            loss_contrastive = criterion(output1,output2,label)\n",
    "            loss_contrastive.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "            if i % 100 == 99:\n",
    "              th.save(net.state_dict(), f\"drive/MyDrive/model-epoch-{epoch}-check-{i}-loss-{loss_contrastive.item()}.pt\")\n",
    "\n",
    "            # Every 10 batches print out the loss\n",
    "            if i % 10 == 0 :\n",
    "              print(f\"Epoch number {epoch} It: {i} Current loss {loss_contrastive.item()}\\n\")\n",
    "              iteration_number += 10\n",
    "\n",
    "              counter.append(iteration_number)\n",
    "              loss.append(loss_contrastive.item())\n",
    "\n",
    "    return net\n",
    "\n",
    "#set the device to cuda\n",
    "device = th.device('cuda' if th.cuda.is_available() else 'cpu')\n",
    "model = train()\n",
    "th.save(model.state_dict(), \"drive/MyDrive/model.pt\")\n",
    "print(\"Model Saved Successfully\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}