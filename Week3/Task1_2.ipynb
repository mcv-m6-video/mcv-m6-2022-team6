{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Task1_2.ipynb","provenance":[{"file_id":"100Z1MClO7iAXSMv1K2Q12_GAoZqAxS48","timestamp":1648487066304},{"file_id":"1KvZ32KOd_nMeS5JSkzpk8Bh8FgAAEWJM","timestamp":1648473958171},{"file_id":"16jcaJoc6bCFAQ96jDe2HwtXj7BMD_-m5","timestamp":1648227706483}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"FsePPpwZSmqt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648511453880,"user_tz":-120,"elapsed":12183,"user":{"displayName":"Sergi Vidal","userId":"04666620063106861026"}},"outputId":"b983c9ee-272b-4575-b20c-f9650e97053f"},"source":["!pip install pyyaml==5.1\n","\n","import torch\n","TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n","CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n","print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n","# Install detectron2 that matches the above pytorch version\n","# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n","!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/$CUDA_VERSION/torch$TORCH_VERSION/index.html\n","# If there is not yet a detectron2 release that matches the given torch + CUDA version, you need to install a different pytorch.\n","\n","# exit(0)  # After installation, you may need to \"restart runtime\" in Colab. This line can also restart runtime"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pyyaml==5.1 in /usr/local/lib/python3.7/dist-packages (5.1)\n","torch:  1.10 ; cuda:  cu111\n","Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu111/torch1.10/index.html\n","Requirement already satisfied: detectron2 in /usr/local/lib/python3.7/dist-packages (0.6+cu111)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from detectron2) (3.2.2)\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.1.0)\n","Requirement already satisfied: pydot in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.3.0)\n","Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.7/dist-packages (from detectron2) (4.63.0)\n","Requirement already satisfied: iopath<0.1.10,>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.1.9)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.8.9)\n","Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from detectron2) (2.0.4)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.3.0)\n","Requirement already satisfied: omegaconf>=2.1 in /usr/local/lib/python3.7/dist-packages (from detectron2) (2.1.1)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.16.0)\n","Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.7/dist-packages (from detectron2) (7.1.2)\n","Requirement already satisfied: fvcore<0.1.6,>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.1.5.post20220305)\n","Requirement already satisfied: hydra-core>=1.1 in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.1.1)\n","Requirement already satisfied: black==21.4b2 in /usr/local/lib/python3.7/dist-packages (from detectron2) (21.4b2)\n","Requirement already satisfied: yacs>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.1.8)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from detectron2) (2.8.0)\n","Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (3.10.0.2)\n","Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (0.4.3)\n","Requirement already satisfied: pathspec<1,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (0.9.0)\n","Requirement already satisfied: regex>=2020.1.8 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (2022.3.15)\n","Requirement already satisfied: click>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (7.1.2)\n","Requirement already satisfied: typed-ast>=1.4.2 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (1.5.2)\n","Requirement already satisfied: toml>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (0.10.2)\n","Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (1.4.4)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2) (5.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2) (1.21.5)\n","Requirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.7/dist-packages (from hydra-core>=1.1->detectron2) (4.8)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core>=1.1->detectron2) (5.4.0)\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from iopath<0.1.10,>=0.1.7->detectron2) (2.4.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (0.11.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (3.0.7)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (1.4.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->detectron2) (1.15.0)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->hydra-core>=1.1->detectron2) (3.7.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.35.0)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (3.17.3)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.0.1)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (0.37.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.0.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (2.23.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (0.6.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (3.3.6)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (57.4.0)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.44.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.8.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (0.4.6)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2) (4.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->detectron2) (4.11.3)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2) (0.4.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (3.0.4)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (3.2.0)\n"]}]},{"cell_type":"code","metadata":{"id":"ZyAvNCJMmvFF","executionInfo":{"status":"ok","timestamp":1648511454897,"user_tz":-120,"elapsed":1032,"user":{"displayName":"Sergi Vidal","userId":"04666620063106861026"}}},"source":["# Some basic setup:\n","# Setup detectron2 logger\n","import detectron2\n","from detectron2.utils.logger import setup_logger\n","setup_logger()\n","\n","# import some common libraries\n","import numpy as np\n","from sklearn.model_selection import KFold\n","import os, json, cv2, random, sys\n","# import some common detectron2 utilities\n","from detectron2 import model_zoo\n","from detectron2.engine import DefaultPredictor, HookBase\n","from detectron2.config import get_cfg\n","from detectron2.utils.visualizer import Visualizer\n","from detectron2.data import MetadataCatalog, DatasetCatalog, build_detection_test_loader, build_detection_train_loader\n","from detectron2.utils import comm\n","from detectron2.structures import BoxMode\n","from detectron2.engine import DefaultTrainer\n","from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n","from detectron2.data import build_detection_test_loader\n","from detectron2.modeling import build_model\n","from detectron2.checkpoint import DetectionCheckpointer\n","\n","import argparse"],"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QzSUtLbGCF34","executionInfo":{"status":"ok","timestamp":1648511457098,"user_tz":-120,"elapsed":2207,"user":{"displayName":"Sergi Vidal","userId":"04666620063106861026"}},"outputId":"c1af7b2d-e4bb-4efd-f17a-52cf388986d1"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/M6-T6-Project-master/week3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hxq6Wc29CHxl","executionInfo":{"status":"ok","timestamp":1648511457099,"user_tz":-120,"elapsed":14,"user":{"displayName":"Sergi Vidal","userId":"04666620063106861026"}},"outputId":"b5014633-5ee5-448f-d229-53d662f273b1"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/M6-T6-Project-master/week3\n"]}]},{"cell_type":"code","source":["#!python inference_taska.py"],"metadata":{"id":"P1o7ZoolCJXn","executionInfo":{"status":"ok","timestamp":1648511457099,"user_tz":-120,"elapsed":11,"user":{"displayName":"Sergi Vidal","userId":"04666620063106861026"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["#!pip install xmltodict\n","sys.path.append('../week1')\n","from utils_week1 import read_annotations\n","#import bounding_box\n","\n","#from LossEvalHook import *\n","#from MyTrainerAugm import *"],"metadata":{"id":"A4cdTcVg48Fi","executionInfo":{"status":"ok","timestamp":1648511457100,"user_tz":-120,"elapsed":11,"user":{"displayName":"Sergi Vidal","userId":"04666620063106861026"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def parse_annotation(annotations):\n","    objs = []\n","    for annot in annotations:\n","\n","        bbox = [annot[0], annot[1], annot[2], annot[3]]\n","\n","        obj = {\n","            \"bbox\": bbox,\n","            \"bbox_mode\": BoxMode.XYXY_ABS,\n","            \"category_id\": 0\n","        }\n","\n","        objs.append(obj)\n","\n","    return objs"],"metadata":{"id":"DJd5UEmn5rQ6","executionInfo":{"status":"ok","timestamp":1648511457101,"user_tz":-120,"elapsed":12,"user":{"displayName":"Sergi Vidal","userId":"04666620063106861026"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def load_dataset(type, thing_classes):\n","\n","    frames_path = '../data/images'\n","    gt_path = '../data/ai_challenge_s03_c010-full_annotation.xml'\n","\n","    gt = read_annotations(gt_path, use_parked=True)\n","\n","    num_frames = 2141\n","\n","    frame_list = np.arange(0,2141)\n","\n","    train_val_split = 0.67\n","    # train_val_split = 1.0\n","\n","    if type == 'train':\n","        init_frame = 0\n","        last_frame = int(train_val_split*(int(num_frames*0.25)))\n","    elif type == 'val' or type == 'test':\n","        init_frame = int(train_val_split*(int(num_frames*0.25)))\n","        last_frame = int(num_frames*0.25)\n","    # elif type == 'test':\n","    #     init_frame = int(num_frames*0.25)\n","    #     last_frame = num_frames\n","    \n","    dataset_dicts = []\n","    for frame_id in range(init_frame, last_frame):\n","        record = {}\n","        filename = os.path.join(frames_path, \"%04d.jpeg\" % (frame_id+1))\n","\n","        record[\"file_name\"] = filename\n","        # record[\"image_id\"] = i+j\n","        record[\"image_id\"] = filename\n","        record[\"height\"] = 1080\n","        record[\"width\"] = 1920\n","\n","        record[\"annotations\"] = parse_annotation(gt[frame_id])\n","        dataset_dicts.append(record)\n","\n","    return dataset_dicts"],"metadata":{"id":"mj3Tt2er5xsa","executionInfo":{"status":"ok","timestamp":1648511457101,"user_tz":-120,"elapsed":11,"user":{"displayName":"Sergi Vidal","userId":"04666620063106861026"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# ValidationLoss (monitor the validation loss)\n","class ValidationLoss(HookBase):\n","    def __init__(self, cfg):\n","        super().__init__()\n","        self.cfg = cfg.clone()\n","        self.cfg.DATASETS.TRAIN = cfg.DATASETS.TEST\n","        self._loader = iter(build_detection_train_loader(self.cfg))\n","\n","    def after_step(self):\n","        data = next(self._loader)\n","        with torch.no_grad():\n","            loss_dict = self.trainer.model(data)\n","\n","            losses = sum(loss_dict.values())\n","            assert torch.isfinite(losses).all(), loss_dict\n","\n","            loss_dict_reduced = {\"val_\" + k: v.item() for k, v in\n","                                 comm.reduce_dict(loss_dict).items()}\n","            losses_reduced = sum(loss for loss in loss_dict_reduced.values())\n","            if comm.is_main_process():\n","                self.trainer.storage.put_scalars(total_val_loss=losses_reduced,\n","                                                 **loss_dict_reduced)\n"],"metadata":{"id":"PpX_rkQy2Iv6","executionInfo":{"status":"ok","timestamp":1648511457102,"user_tz":-120,"elapsed":12,"user":{"displayName":"Sergi Vidal","userId":"04666620063106861026"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["#args = parse_args()\n","\n","model = 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml'  #pre-trained detectron2 model\n","print('[INFO] Using model: ', model)\n","\n","#Hyper-parameters\n","lr= 0.001      #learning rate\n","epochs= 100    #max iterations (epochs)\n","batch= 512     #batch size\n","#augm=True     #use augmentation\n","#freeze=2      #stages of ResNet to freeze\n","\n","\n","###-------TRAIN-----------------------------\n","cfg = get_cfg()\n","\n","cfg.merge_from_file(model_zoo.get_config_file(model))\n","cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n","cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(model)\n","\n","cfg.OUTPUT_DIR = 'results/task1_2/' + 'faster_rcnn' + '/lr_' + str(lr).replace('.', '_') + '_iter_' + str(epochs) + '_batch_' + str(batch) + '/' \n","os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n","\n","thing_classes = ['Car']\n","dataset='AICity'\n","\n","for d in ['train', 'val', 'test']:\n","  DatasetCatalog.register(dataset + '_' + d, lambda d=d: load_dataset(d, thing_classes))\n","  MetadataCatalog.get(dataset + '_' + d).set(thing_classes=thing_classes)\n","\n","metadata = MetadataCatalog.get(dataset + '_train')\n","\n","cfg.DATASETS.TRAIN = (dataset + '_train',)\n","cfg.DATASETS.VAL = (dataset + '_val',)\n","cfg.DATASETS.TEST = (dataset + '_test',)\n","cfg.DATALOADER.NUM_WORKERS = 2\n","cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(thing_classes)\n","cfg.SOLVER.IMS_PER_BATCH = 2\n","\n","#cfg.MODEL.BACKBONE.FREEZE_AT = args.freeze\n","\n","cfg.SOLVER.BASE_LR = lr\n","cfg.SOLVER.MAX_ITER = epochs\n","cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = batch\n","\n","#eval_period: frequence of validation loss computations (to plot curves)\n","cfg.TEST.EVAL_PERIOD = 0\n","\n","#if args.augm:\n","#    trainer = MyTrainerAugm(cfg)\n","#else:\n","#    trainer = MyTrainer(cfg)\n","\n","trainer = DefaultTrainer(cfg)\n","val_loss = ValidationLoss(cfg)\n","trainer.register_hooks([val_loss])\n","# swap the order of PeriodicWriter and ValidationLossl\n","trainer._hooks = trainer._hooks[:-2] + trainer._hooks[-2:][::-1]\n","trainer.resume_or_load(resume=False)\n","trainer.train()\n","\n","\n","###-------INFERENCE AND EVALUATION---------------------------\n","cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n","\n","### MAP #####\n","#We can also evaluate its performance using AP metric implemented in COCO API.\n","evaluator = COCOEvaluator(dataset + '_val', cfg, False, output_dir=cfg.OUTPUT_DIR)\n","test_loader = build_detection_test_loader(cfg, dataset + '_val')\n","print('------------------------ Evaluating model ' + model + ' on validation set ---------------------------------')\n","print(inference_on_dataset(trainer.model, test_loader, evaluator))\n","print('---------------------------------------------------------')\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nx7W1wcQ6r65","outputId":"aa103d6c-c379-4e5e-cabf-b6abfefd5fb2","executionInfo":{"status":"ok","timestamp":1648511745986,"user_tz":-120,"elapsed":288896,"user":{"displayName":"Sergi Vidal","userId":"04666620063106861026"}}},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["[INFO] Using model:  COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\n","\u001b[32m[03/28 23:51:00 d2.engine.defaults]: \u001b[0mModel:\n","GeneralizedRCNN(\n","  (backbone): FPN(\n","    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (top_block): LastLevelMaxPool()\n","    (bottom_up): ResNet(\n","      (stem): BasicStem(\n","        (conv1): Conv2d(\n","          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n","          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","        )\n","      )\n","      (res2): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res3): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res4): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (4): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (5): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res5): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (proposal_generator): RPN(\n","    (rpn_head): StandardRPNHead(\n","      (conv): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n","      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","    (anchor_generator): DefaultAnchorGenerator(\n","      (cell_anchors): BufferList()\n","    )\n","  )\n","  (roi_heads): StandardROIHeads(\n","    (box_pooler): ROIPooler(\n","      (level_poolers): ModuleList(\n","        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n","        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n","        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n","        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n","      )\n","    )\n","    (box_head): FastRCNNConvFCHead(\n","      (flatten): Flatten(start_dim=1, end_dim=-1)\n","      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n","      (fc_relu1): ReLU()\n","      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n","      (fc_relu2): ReLU()\n","    )\n","    (box_predictor): FastRCNNOutputLayers(\n","      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n","      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n","    )\n","  )\n",")\n","\u001b[32m[03/28 23:51:00 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 358 images left.\n","\u001b[32m[03/28 23:51:01 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n","\u001b[36m|  category  | #instances   |\n","|:----------:|:-------------|\n","|    Car     | 3356         |\n","|            |              |\u001b[0m\n","\u001b[32m[03/28 23:51:01 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n","\u001b[32m[03/28 23:51:01 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n","\u001b[32m[03/28 23:51:01 d2.data.common]: \u001b[0mSerializing 358 elements to byte tensors and concatenating them all ...\n","\u001b[32m[03/28 23:51:01 d2.data.common]: \u001b[0mSerialized dataset takes 0.39 MiB\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/28 23:51:01 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n","\u001b[32m[03/28 23:51:07 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 177 images left.\n","\u001b[32m[03/28 23:51:07 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n","\u001b[36m|  category  | #instances   |\n","|:----------:|:-------------|\n","|    Car     | 2124         |\n","|            |              |\u001b[0m\n","\u001b[32m[03/28 23:51:07 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n","\u001b[32m[03/28 23:51:07 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n","\u001b[32m[03/28 23:51:07 d2.data.common]: \u001b[0mSerializing 177 elements to byte tensors and concatenating them all ...\n","\u001b[32m[03/28 23:51:07 d2.data.common]: \u001b[0mSerialized dataset takes 0.24 MiB\n"]},{"output_type":"stream","name":"stderr","text":["Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n","Some model parameters or buffers are not found in the checkpoint:\n","\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n","\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[32m[03/28 23:51:09 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  max_size = (max_size + (stride - 1)) // stride * stride\n","/usr/local/lib/python3.7/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[32m[03/28 23:51:53 d2.utils.events]: \u001b[0m eta: 0:01:56  iter: 19  total_loss: 1.554  loss_cls: 0.639  loss_box_reg: 0.8514  loss_rpn_cls: 0.02584  loss_rpn_loc: 0.03587  total_val_loss: 1.565  val_loss_cls: 0.6203  val_loss_box_reg: 0.8712  val_loss_rpn_cls: 0.02285  val_loss_rpn_loc: 0.04501  time: 1.4157  data_time: 0.0785  lr: 0.00019081  max_mem: 2639M\n","\u001b[32m[03/28 23:52:34 d2.utils.events]: \u001b[0m eta: 0:01:27  iter: 39  total_loss: 1.26  loss_cls: 0.38  loss_box_reg: 0.8352  loss_rpn_cls: 0.01476  loss_rpn_loc: 0.03221  total_val_loss: 1.289  val_loss_cls: 0.3843  val_loss_box_reg: 0.8519  val_loss_rpn_cls: 0.01633  val_loss_rpn_loc: 0.03858  time: 1.4342  data_time: 0.0073  lr: 0.00039061  max_mem: 2639M\n","\u001b[32m[03/28 23:53:15 d2.utils.events]: \u001b[0m eta: 0:00:57  iter: 59  total_loss: 1.079  loss_cls: 0.2362  loss_box_reg: 0.797  loss_rpn_cls: 0.009985  loss_rpn_loc: 0.02417  total_val_loss: 1.115  val_loss_cls: 0.282  val_loss_box_reg: 0.7856  val_loss_rpn_cls: 0.01049  val_loss_rpn_loc: 0.03177  time: 1.4218  data_time: 0.0081  lr: 0.00059041  max_mem: 2639M\n","\u001b[32m[03/28 23:53:57 d2.utils.events]: \u001b[0m eta: 0:00:28  iter: 79  total_loss: 0.8498  loss_cls: 0.1754  loss_box_reg: 0.6551  loss_rpn_cls: 0.003877  loss_rpn_loc: 0.02374  total_val_loss: 0.8761  val_loss_cls: 0.2021  val_loss_box_reg: 0.6221  val_loss_rpn_cls: 0.005374  val_loss_rpn_loc: 0.03239  time: 1.4291  data_time: 0.0077  lr: 0.00079021  max_mem: 2639M\n","\u001b[32m[03/28 23:54:39 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 99  total_loss: 0.6293  loss_cls: 0.1511  loss_box_reg: 0.4669  loss_rpn_cls: 0.002948  loss_rpn_loc: 0.01955  total_val_loss: 0.6526  val_loss_cls: 0.166  val_loss_box_reg: 0.4435  val_loss_rpn_cls: 0.005235  val_loss_rpn_loc: 0.03264  time: 1.4324  data_time: 0.0073  lr: 0.00099001  max_mem: 2639M\n","\u001b[32m[03/28 23:54:39 d2.engine.hooks]: \u001b[0mOverall training speed: 98 iterations in 0:02:20 (1.4324 s / it)\n","\u001b[32m[03/28 23:54:39 d2.engine.hooks]: \u001b[0mTotal training time: 0:03:24 (0:01:03 on hooks)\n","\u001b[32m[03/28 23:54:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n","\u001b[32m[03/28 23:54:40 d2.data.common]: \u001b[0mSerializing 177 elements to byte tensors and concatenating them all ...\n","\u001b[32m[03/28 23:54:40 d2.data.common]: \u001b[0mSerialized dataset takes 0.24 MiB\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/28 23:54:40 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/28 23:54:40 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n","\u001b[32m[03/28 23:54:40 d2.evaluation.coco_evaluation]: \u001b[0mTrying to convert 'AICity_val' to COCO format ...\n","\u001b[32m[03/28 23:54:40 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'AICity_val' to COCO format ...)\n","\u001b[32m[03/28 23:54:41 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n","\u001b[32m[03/28 23:54:41 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 177, #annotations: 2124\n","\u001b[32m[03/28 23:54:42 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at 'results/task1_2/faster_rcnn/lr_0_001_iter_100_batch_512/AICity_val_coco_format.json' ...\n","\u001b[32m[03/28 23:54:43 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n","\u001b[32m[03/28 23:54:43 d2.data.common]: \u001b[0mSerializing 177 elements to byte tensors and concatenating them all ...\n","\u001b[32m[03/28 23:54:43 d2.data.common]: \u001b[0mSerialized dataset takes 0.24 MiB\n","------------------------ Evaluating model COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml on validation set ---------------------------------\n","\u001b[32m[03/28 23:54:43 d2.evaluation.evaluator]: \u001b[0mStart inference on 177 batches\n","\u001b[32m[03/28 23:54:47 d2.evaluation.evaluator]: \u001b[0mInference done 11/177. Dataloading: 0.0020 s/iter. Inference: 0.3441 s/iter. Eval: 0.0004 s/iter. Total: 0.3465 s/iter. ETA=0:00:57\n","\u001b[32m[03/28 23:54:52 d2.evaluation.evaluator]: \u001b[0mInference done 26/177. Dataloading: 0.0026 s/iter. Inference: 0.3434 s/iter. Eval: 0.0004 s/iter. Total: 0.3466 s/iter. ETA=0:00:52\n","\u001b[32m[03/28 23:54:57 d2.evaluation.evaluator]: \u001b[0mInference done 41/177. Dataloading: 0.0026 s/iter. Inference: 0.3441 s/iter. Eval: 0.0003 s/iter. Total: 0.3472 s/iter. ETA=0:00:47\n","\u001b[32m[03/28 23:55:03 d2.evaluation.evaluator]: \u001b[0mInference done 56/177. Dataloading: 0.0025 s/iter. Inference: 0.3434 s/iter. Eval: 0.0003 s/iter. Total: 0.3464 s/iter. ETA=0:00:41\n","\u001b[32m[03/28 23:55:08 d2.evaluation.evaluator]: \u001b[0mInference done 71/177. Dataloading: 0.0026 s/iter. Inference: 0.3433 s/iter. Eval: 0.0003 s/iter. Total: 0.3464 s/iter. ETA=0:00:36\n","\u001b[32m[03/28 23:55:13 d2.evaluation.evaluator]: \u001b[0mInference done 86/177. Dataloading: 0.0025 s/iter. Inference: 0.3437 s/iter. Eval: 0.0003 s/iter. Total: 0.3466 s/iter. ETA=0:00:31\n","\u001b[32m[03/28 23:55:18 d2.evaluation.evaluator]: \u001b[0mInference done 101/177. Dataloading: 0.0024 s/iter. Inference: 0.3437 s/iter. Eval: 0.0003 s/iter. Total: 0.3466 s/iter. ETA=0:00:26\n","\u001b[32m[03/28 23:55:23 d2.evaluation.evaluator]: \u001b[0mInference done 116/177. Dataloading: 0.0024 s/iter. Inference: 0.3446 s/iter. Eval: 0.0003 s/iter. Total: 0.3474 s/iter. ETA=0:00:21\n","\u001b[32m[03/28 23:55:29 d2.evaluation.evaluator]: \u001b[0mInference done 131/177. Dataloading: 0.0024 s/iter. Inference: 0.3446 s/iter. Eval: 0.0003 s/iter. Total: 0.3475 s/iter. ETA=0:00:15\n","\u001b[32m[03/28 23:55:34 d2.evaluation.evaluator]: \u001b[0mInference done 146/177. Dataloading: 0.0024 s/iter. Inference: 0.3445 s/iter. Eval: 0.0003 s/iter. Total: 0.3474 s/iter. ETA=0:00:10\n","\u001b[32m[03/28 23:55:39 d2.evaluation.evaluator]: \u001b[0mInference done 161/177. Dataloading: 0.0024 s/iter. Inference: 0.3445 s/iter. Eval: 0.0003 s/iter. Total: 0.3474 s/iter. ETA=0:00:05\n","\u001b[32m[03/28 23:55:44 d2.evaluation.evaluator]: \u001b[0mInference done 176/177. Dataloading: 0.0023 s/iter. Inference: 0.3444 s/iter. Eval: 0.0003 s/iter. Total: 0.3472 s/iter. ETA=0:00:00\n","\u001b[32m[03/28 23:55:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:59.779565 (0.347556 s / iter per device, on 1 devices)\n","\u001b[32m[03/28 23:55:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:59 (0.344342 s / iter per device, on 1 devices)\n","\u001b[32m[03/28 23:55:45 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n","\u001b[32m[03/28 23:55:45 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to results/task1_2/faster_rcnn/lr_0_001_iter_100_batch_512/coco_instances_results.json\n","\u001b[32m[03/28 23:55:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n","Loading and preparing results...\n","DONE (t=0.00s)\n","creating index...\n","index created!\n","\u001b[32m[03/28 23:55:45 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n","\u001b[32m[03/28 23:55:45 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.06 seconds.\n","\u001b[32m[03/28 23:55:45 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n","\u001b[32m[03/28 23:55:45 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.662\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.924\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.691\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.600\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.906\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.076\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.628\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.704\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.646\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.937\n","\u001b[32m[03/28 23:55:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n","|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n","|:------:|:------:|:------:|:-----:|:------:|:------:|\n","| 66.232 | 92.403 | 69.075 |  nan  | 59.990 | 90.637 |\n","\u001b[32m[03/28 23:55:45 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n","OrderedDict([('bbox', {'AP': 66.23195891368218, 'AP50': 92.40348764227484, 'AP75': 69.07487870761759, 'APs': nan, 'APm': 59.98987461630414, 'APl': 90.63665688481193})])\n","---------------------------------------------------------\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"qRPFPYI77t4j","executionInfo":{"status":"ok","timestamp":1648511745987,"user_tz":-120,"elapsed":7,"user":{"displayName":"Sergi Vidal","userId":"04666620063106861026"}}},"execution_count":10,"outputs":[]}]}